# Use of boilerplate language in regulatory documents: Evidence from Environmental Impact Statements

This repository subdirectory correspond to the following paper published in the Journal of Public Administration Research & Theory, [DOI and link to be filled in]. The tuolumne repository contains a variety of elements broadly related to the management and implementation of environmental impact assessment (EIA) under the U.S. National Environmental Policy Act. In this specific paper, we the use of boilerplate text in EIA.

This subdirectory contains all of the data and code materials necessary to replicate the project. For questions, please raise an issue and tag us here on Github.

## Paper Abstract

Administrative procedures are intended to increase transparency and help agencies make better decisions. However, these requirements also increase agency workload. Understanding how public agencies satisfy procedural requirements is a critical facet of agency performance. This analysis focuses on the language agencies use in Environmental Impact Statements (EISs) required by the U.S. National Environmental Policy Act (NEPA) – specifically, the reuse of similar text within and between assessments. We synthesize theories of institutional isomorphism and bureaucratic coping to understand why and how text is reused, and consider the tradeoffs associated with this behavior. Using a national dataset of 1015 EISs published by 22 U.S. agencies from 2013 to 2020, we explore how boilerplate language varies by agency, authors, project type, location, and consulting firm involvement. We find that text reuse primarily occurs where there is a clear substantive rationale for boilerplate language or where studies share authors or contract consulting firms. This indicates: (1) that agencies largely do not merely engage in pro forma compliance efforts; and (2) that while NEPA procedures are oriented around individual projects and decisions, cross-project learning and the narrowness – or breadth – of agencies’ project portfolios shape analytical routines and the relative tradeoffs of boilerplate text in policy analysis. This paper adds to our theoretical understanding of agencies’ coping strategies in response to institutional pressures and makes a methodological contribution by demonstrating the application of text reuse measurement and information extraction methods in public administration research.


## Getting Started

### Dependencies

* The project requires the R statistical programming language, version 4.1.1 (2021-08-10). The project has not been tested on Windows, but it was developed jointly in OSX (11.4) and Linux. Some of the R packages required might require loading underlying dependencies (e.g., if you use the rgdal package, the GDAL and PROJ libraries must be installed).

### Installing

* The boilerplate_project subdirectory is designed to run as a self-contained folder. Data inputs are either stored in the subdirectory or read directly from online locations. Specifically, the raw text input data are stored in the DataDryad repository, doi:10.25338/B80K9R: https://datadryad.org/stash/share/0lRK6azV9HS_3QjARgYW2VAtoOzwpNcw_a3RXDSWbVE . The project is designed to download the data from Dryad and then replicate within the subdirectory without further modification.

### Subdirectory items

The subdirectory has 4 folders:
- code: scripts for replicating the project
- data_products: intermediate data objects and model objects generated by the project scripts (e.g., the subset of projects and documents used for the final sample and analysis, entity extractions, geotagged objects, etc.). The code is designed such that these objects can be generated anew or else take as-is if someone wants to skip ahead a few steps.
- input: THIS FOLDER IS EMPTY AND DESIGNED TO BE FILLED BY DOWNLOADING THE DATA FROM DATADRYAD. These inputs (https://datadryad.org/stash/dataset/doi:10.25338/B80K9R) are as follows:

1. feis_corpus_2013-2020.rds

This is an RDS compressed data.table object (https://cran.r-project.org/web/packages/data.table/) in which each page is a row. The data.table has three columns, showing the File, text, and page #.

2. feis_document_record.csv

This CSV file itemizes documents in the e-nepa database (https://cdxnodengn.epa.gov/cdx-enepa-public/action/eis/search) by row, and provides meta-data for each document. Projects and documents are linked by EIS Number (an 8-digit identifier in which the first four digits show the year of publication). Every file (document) is saved with the EIS Number appended to the front of the file name, followed by an underscore, and then the original file name as downloaded from the EPA website.

3. feis_record_detail.csv

This CSV file itemizes projects in the e-nepa database (https://cdxnodengn.epa.gov/cdx-enepa-public/action/eis/search) by row, and provides meta-data for each project.

4. detected_preparer_pages_uncleaned.rds

This file contains plain text that is fed into the entity extraction model to identify preparers and consultants. The entity extraction R script in the project github repository shows how these pages were identified. The reason the plain text in the primary corpus is not used is that the primary corpus removes extra spaces, formatting tags, and other noise that is not relevant to the primary analysis but is potentially useful in entity extraction (e.g., line breaks, multiple spaces between names, etc.). Thus, this corpus is derived from the same original data, but the text is slightly different.


## Help

Please feel free to ping us if any links appear broken. Note that in some case, the call periodically throws an error for reasons that appear due to the idiosyncrasies of various online portals—this is often solved simply by waiting a minute and trying again.


## Authors

Contributors names and contact info


Tyler A. Scott, tascott@ucdavis.edu, @tylerscottphd  
Nicholas Marantz, nmarantz@ucdavis.edu
Nicola Ulibarri, ulibarri@uci.edu


## License

This project is licensed under the MIT License - see the LICENSE.md file for details

